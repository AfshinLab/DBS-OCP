import os
from subprocess import CalledProcessError

from snakemake.utils import validate

from dbsocp.utils import revcomp

configfile: "dbsocp.yaml"
validate(config, "config.schema.yaml")


inputs_preprocess = [
    "trimmed.barcoded.1.fastq.gz",
    "trimmed.barcoded.2.fastq.gz",
    "trimmed.barcoded.1_fastqc.html",
    "trimmed.barcoded.2_fastqc.html",
    "barcodes_fastqc.html"
]

inputs_align = [
    "mapped.bam",
    "preseq_c_curve.txt"
]

inputs_snaptools = [
    "mapped.snap",
    "mapped.snap.qc",
    "add_bmat.done"
]

inputs_archr = [
    "fragments.merged.tsv.gz",
    "fragments.merged.tsv.gz.tbi",
]

if config["index"] is None:
    include: "rules/trim_v1.smk"
else:
    include: "rules/trim_v2.smk"

rule final:
    input: inputs_preprocess, inputs_align, inputs_snaptools, inputs_archr


rule archr:
    """Apply ArchR to data"""
    input: inputs_archr


rule snaptools:
    """Apply SnapTools to data"""
    input: inputs_snaptools


rule align:
    """Align reads and generate SNAP files for downstream analysis"""
    input: inputs_align


rule preprocess:
    """Preprocess FASTQs to get trimmed and barcoded files"""
    input: inputs_preprocess


rule tag:
    """Tag reads with uncorrected and corrected barcode."""
    output:
        r1_fastq="trimmed.barcoded.1.fastq.gz",
        r2_fastq="trimmed.barcoded.2.fastq.gz"
    input:
        interleaved_fastq="trimmed.fastq",
        uncorrected_barcodes="barcodes.fastq.gz",
        corrected_barcodes="barcodes.clstr.gz"
    log: "trimmed.barcoded.1.fastq.gz.log"
    threads: 1
    params: 
        barcode_pattern = config["barcode"] if config["index"] is not None else revcomp(config["barcode"]),
        min_count = config["min_count"]
    shell:
        "dbsocp tagfastq"
        " --o1 {output.r1_fastq}"
        " --o2 {output.r2_fastq}"
        " --min-count {params.min_count}"
        " --pattern-match {params.barcode_pattern}"
        " {input.uncorrected_barcodes}"
        " {input.corrected_barcodes}"
        " {input.interleaved_fastq}"
        " 2> {log}"


rule starcode_clustering:
    """Cluster DBS barcodes using starcode"""
    output:
        "barcodes.clstr.gz"
    input:
        "barcodes.fastq.gz"
    threads: 20
    log: "barcodes.clstr.gz.log"
    params:
        barcode_max_dist = config["barcode_max_dist"],
        barcode_ratio = config["barcode_ratio"]
    shell:
        "pigz -cd {input} |"
        " starcode"
        " -t {threads}"
        " -d {params.barcode_max_dist}"
        " -r {params.barcode_ratio}"
        " --print-clusters"
        " 2> {log}"
        " | pigz -9 > {output}"


rule fastqc:
    """Create FastQC reports for FASTQs"""
    output:
        qc = "{base}_fastqc.html",
        zip = "{base}_fastqc.zip",
    input:
        reads = "{base}.fastq.gz",
    log: "{base}_fastqc.log"
    threads: 2  # Fix java.lang.OutOfMemoryError (https://github.com/s-andrews/FastQC/issues/24)
    shell:
        "fastqc {input.reads} -t {threads} 2> {log}"


rule map:
    """Align reads to reference, mark duplicates and sort by coordinate"""
    output:
        bam = "mapped.bam"
    input:
        fastq1 = "trimmed.barcoded.1.fastq.gz",
        fastq2 = "trimmed.barcoded.2.fastq.gz"
    log:
        map = "mapped.bam.map.log",
        sort = "mapped.bam.sort.log"
    threads: 20
    params:
        tmpdir = "-T $TMPDIR" if "TMPDIR" in os.environ else "",
        reference = config["reference"]
    shell:
        "bwa mem"
        " -t {threads}"
        " -C"
        " -M"
        " {params.reference}"
        " {input.fastq1}"
        " {input.fastq2}"
        " 2> {log.map}"
        " |"
        " samtools sort -"
        " -@ {threads}"
        " -o {output.bam}"
        " {params.tmpdir}"
        " 2> {log.sort}"


rule sort:
    """Sort BAM by name"""
    output:
        bam = "mapped.nsort.bam"
    input:
        bam = "mapped.bam"
    log: "mapped.nsort.bam.log"
    threads: 20
    params:
        tmpdir = "-T $TMPDIR" if "TMPDIR" in os.environ else ""
    shell:
        " samtools sort"
        " -n"
        " -@ {threads}"
        " -o {output.bam}"
        " {params.tmpdir}"
        " {input.bam}"
        " 2> {log}"


rule index:
    """Index coordinate sorted BAM"""
    output:
        bai = "{base}.bam.bai"
    input:
        bam = "{base}.bam"
    threads: 20
    shell:
        " samtools index -@ {threads} {input.bam}"


rule snaptools_pre:
    """Convert pair-end reads into fragments and for each fragment check: mapping 
    quality, proper pairing, length, duplicates. Generates a snap-format 
    (Single-Nucleus Accessibility Profiles) file and QC file."""
    output:
        snap = "mapped.snap",
        snap_qc = "mapped.snap.qc",
    input:
        bam = "mapped.nsort.bam"
    log: "mapped.snap.log"
    threads: 20
    params:
        reference_name = config["reference_name"],
        fai = config["reference"] + ".fai"
    shell:
        "snaptools snap-pre"
        " --input-file={input.bam}"
        " --output-snap={output.snap}"
        " --genome-name={params.reference_name}"
        # For genome-size -> file with chromosome name and length on 1st and 2nd column
        " --genome-size={params.fai}" 
        " --min-mapq=30"
        " --min-flen=0"
        " --max-flen=1000"
        " --keep-chrm=TRUE"
        " --keep-single=FALSE"
        " --keep-secondary=FALSE"
        " --overwrite=True"
        " --max-num=1000000"
        " --min-cov=100"
        " --verbose=True 2> {log}"


rule snaptools_add_bmat:
    """Convert pair-end reads into fragments and for each fragment check: mapping 
    quality, proper pairing, length, duplicates. Generates a snap-format 
    (Single-Nucleus Accessibility Profiles) file and QC file."""
    output:
        done = temp("add_bmat.done")
    input:
        snap = "mapped.snap"
    log: "mapped.snap.add_bmat.log"
    threads: 20
    params:
        bin_sizes = config["bin_sizes"]
    shell:
        # Rule cannot be rerun without frist deleting current session.
        # Try deleting first and then generate bmat.
        "snaptools snap-del"
        " --snap-file={input.snap}"
        " --session-name AM"
        " || true;"
        " snaptools snap-add-bmat"
        " --snap-file={input.snap}"
        " --bin-size-list {params.bin_sizes}"
        " --verbose=True > {log}"
        " &&"
        " touch {output}"


rule getfrags:
    output:
        frags = "fragments.tsv"
    input:
        bam = "mapped.bam",
        bai = "mapped.bam.bai"
    log: "fragments.tsv.log"
    shell:
        "dbsocp getfrags"
        " -o {output.frags}"
        " {input.bam}"
        " 2> {log}"


rule mergedups:
    output:
        frags = "fragments.merged.tsv",
        merges = "barcode_merges.tsv"
    input:
        frags = "fragments.tsv.gz",
        index = "fragments.tsv.gz.tbi"
    log: "fragments.merged.tsv.log"
    shell:
        "dbsocp mergedups"
        " -o {output.frags}"
        " -m {output.merges}"
        " --threshold 0.2"
        " {input.frags}"
        " 2> {log}"


rule index_frags:
    output:
        frags = "{base}.tsv.gz",
        tbi = "{base}.tsv.gz.tbi"
    input:
        frags = "{base}.tsv"
    shell:
        "bgzip -c {input.frags} > {output.frags} && tabix -p bed {output.frags}"


rule preseq_c_curve:
    output:
        "preseq_c_curve.txt"
    input:
        "mapped.bam"
    shell:
        "preseq c_curve"
        " -o {output}"
        " -bam {input}"
        " -pe"
        " --seg_len 10000000"

# Run MultiQC as a final set
onsuccess:
    print("Running MultiQC:")
    shell("multiqc -f . --zip-data-dir")
