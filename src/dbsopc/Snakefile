import os

from snakemake.utils import validate

configfile: "dbsopc.yaml"
validate(config, "config.schema.yaml")


inputs_preprocess = [
    "trimmed.barcoded.1.fastq.gz",
    "trimmed.barcoded.2.fastq.gz",
    "trimmed.barcoded.1_fastqc.html",
    "trimmed.barcoded.2_fastqc.html",
    "barcodes_fastqc.html"
]

inputs_align = [
    "mapped.snap",
    "mapped.snap.qc",
]

rule final:
    input: inputs_preprocess, inputs_align


rule align:
    """Align reads and generate SNAP files for downstream analysis"""
    input: inputs_align


rule preprocess:
    """Preprocess FASTQs to get trimmed and barcoded files"""
    input: inputs_preprocess


rule trim:
    """Trim away 5' and possible 3' handles on read1 and trim possible 3' handles on 
    read2."""
    output:
        interleaved_fastq=pipe("trimmed.fastq")
    input:
        r1_fastq="reads.1.fastq.gz",
        r2_fastq="reads.2.fastq.gz",
    log: "trimmed.fastq.log"
    threads: workflow.cores - 1  # rule tag needs one thread
    params:
        five_prime = "XNNN" + config["h1"] + "N"*len(config["barcode"]) + config["h2"],
        trim_len = sum([len(config["h1"]), len(config["barcode"]), len(config["h2"])])
    shell:
        "cutadapt"
        " -g '{params.five_prime};min_overlap={params.trim_len}...{config[h3]};optional'"
        " -A {config[h3]}"
        " --pair-filter 'any'"
        " -e 0.2"
        " -j {threads}"
        " -m 25"
        " --interleaved"
        " -o {output.interleaved_fastq}"
        " {input.r1_fastq}"
        " {input.r2_fastq}"
        " > {log}"


rule tag:
    """Tag reads with uncorrected and corrected barcode."""
    output:
        r1_fastq="trimmed.barcoded.1.fastq.gz",
        r2_fastq="trimmed.barcoded.2.fastq.gz"
    input:
        interleaved_fastq="trimmed.fastq",
        uncorrected_barcodes="barcodes.fastq.gz",
        corrected_barcodes="barcodes.clstr.gz"
    log: "trimmed.barcoded.1.fastq.gz.log"
    threads: 1
    shell:
        "dbsopc tagfastq"
        " --o1 {output.r1_fastq}"
        " --o2 {output.r2_fastq}"
        " --min-count {config[min_count]}"
        " --pattern-match {config[barcode]}"
        " {input.uncorrected_barcodes}"
        " {input.corrected_barcodes}"
        " {input.interleaved_fastq}"
        " 2> {log}"


rule extract_DBS:
    """Extract barcode sequence from read1 FASTQ"""
    output:
        fastq="barcodes.fastq.gz"
    input:
         fastq="reads.1.fastq.gz"
    log: "barcodes.fastq.gz.log"
    threads: 20
    params:
        extract_len = len(config["h1"]),
        dbs_len_max = len(config["barcode"]) + 1,
        dbs_len_min = len(config["barcode"]) - 1
    shell:
        "cutadapt"
        " -g 'XNNN{config[h1]};min_overlap={params.extract_len}...{config[h2]}'"
        " -e 0.2"
        " --discard-untrimmed"
        " -j {threads}"
        " -m {params.dbs_len_min}"
        " -M {params.dbs_len_max}"
        " --max-n 0"
        " -o {output.fastq}"
        " {input.fastq}"
        " > {log}"


rule starcode_clustering:
    """Cluster DBS barcodes using starcode"""
    output:
        "barcodes.clstr.gz"
    input:
        "barcodes.fastq.gz"
    threads: 20
    log: "barcodes.clstr.gz.log"
    shell:
        "pigz -cd {input} |"
        " starcode"
        " -t {threads}"
        " -d {config[barcode_max_dist]}"
        " -r {config[barcode_ratio]}"
        " --print-clusters"
        " 2> {log}"
        " | pigz -9 > {output}"


rule fastqc:
    """Create FastQC reports for FASTQs"""
    output:
        qc = "{base}_fastqc.html",
        zip = "{base}_fastqc.zip",
    input:
        reads = "{base}.fastq.gz",
    log: "{base}_fastqc.log"
    threads: 2  # Fix java.lang.OutOfMemoryError (https://github.com/s-andrews/FastQC/issues/24)
    shell:
        "fastqc {input.reads} -t {threads} 2> {log}"


rule map:
    """Align reads to reference and sort by reads name"""
    output:
        bam = "mapped.bam"
    input:
        fastq1 = "trimmed.barcoded.1.fastq.gz",
        fastq2 = "trimmed.barcoded.2.fastq.gz"
    log: "mapped.bam.log"
    threads: 20
    params:
        tmpdir = "-T $TMPDIR" if "TMPDIR" in os.environ else ""
    shell:
        "(bwa mem"
        " -t {threads}"
        " -C"
        " {config[reference]}"
        " {input.fastq1}"
        " {input.fastq2}"
        " |"
        " samtools sort -"
        " -n"
        " -@ {threads}"
        " -o {output.bam}"
        " {params.tmpdir}) 2> {log}"


rule snaptools_pre:
    """Convert pair-end reads into fragments and for each fragment check: mapping 
    quality, proper pairing, length, duplicates. Generates a snap-format 
    (Single-Nucleus Accessibility Profiles) file and QC file."""
    output:
        snap = "mapped.snap",
        snap_qc = "mapped.snap.qc",
    input:
        bam = "mapped.bam"
    log: "mapped.snap.log"
    threads: 20
    shell:
        "snaptools snap-pre"
        " --input-file={input.bam}"
        " --output-snap={output.snap}"
        " --genome-name={config[reference_name]}"
        # For genome-size -> file with chromosome name and length on 1st and 2nd column
        " --genome-size={config[reference]}.fai" 
        " --min-mapq=30"
        " --min-flen=0"
        " --max-flen=1000"
        " --keep-chrm=TRUE"
        " --keep-single=FALSE"
        " --keep-secondary=FALSE"
        " --overwrite=True"
        " --max-num=1000000"
        " --min-cov=100"
        " --verbose=True 2> {log}"


# Run MultiQC as a final set
onsuccess:
    print("Running MultiQC:")
    shell("multiqc -f . --zip-data-dir")
